{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 03. 합성곱 신경망"
      ],
      "metadata": {
        "id": "aZxLpE-GMFG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 코드부터 작성하기\n",
        "\n",
        "구현 모델: **합성곱 신경망(CNN)**을 이용한 28x28 흑백 이미지를 입력받아 셔츠, 바지, 드레스 등의 종류 구별"
      ],
      "metadata": {
        "id": "x56StG8JMiUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모듈 불러오기"
      ],
      "metadata": {
        "id": "3UHC-KhoAex7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOhmVp9cIHt3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 준비하기"
      ],
      "metadata": {
        "id": "U3-Esn_LAjnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()"
      ],
      "metadata": {
        "id": "ga-_rEuEIpHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow의 합성곱 신경망은 R,G,B 3가지의 채널이 존재하는 이미지에 대해 설계되었기 때문에 채널 차원(dimenssion)을 추가하여야한다.\n",
        "\n",
        "- [`ndarray.reshape(shape, order='C')`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.reshape.html)\n",
        "\n",
        "ndarray.reshape 메소드를 통해 기존 3차원(이미지 개수, 가로 픽셀, 세로 픽셀)이었던 데이터를 4차원(이미지 개수, 가로 픽셀, 세로 픽셀, 채널)으로 데이터를 재정의해준다.\n",
        "\n",
        "기존 데이터는 흑백이므로 채널은 1개만 존재한다.\n",
        "\n",
        "0-255의 값을0-1로 정규화하는 작업도 진행해준다."
      ],
      "metadata": {
        "id": "0uauN09uAmt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "3RYXKMcoI-17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 구성하기\n",
        "\n",
        "레이어 구성:\n",
        "- 입력 (28,28,1) </br>\n",
        "-> Conv2D(64개의 (3x3)필터 채널) + Relu </br>\n",
        "Input: $(28, 28, 1)$ </br>\n",
        "Output: $(26, 26, 64)$, 이미지 4면의 끝쪽 픽셀이 잘림 </br>\n",
        "Params: $640=(inputChannels\\times filtersize+bias)\\times channels=(1\\times3\\times3+1)\\times64$\n",
        "-> MaxPooling2D(2x2 픽셀을 1x1로 압축) </br>\n",
        "Input: $(26, 26, 64)$ </br>\n",
        "Output: $(13, 13, 64)$</br>\n",
        "-> Conv2D(64개의 (3x3)필터 채널) + Relu </br>\n",
        "Input: $(13, 13, 64)$ </br>\n",
        "Output: $(11, 11, 64)$, 이미지 4면의 끝쪽 픽셀이 잘림 </br>\n",
        "Params: $36928=(inputChannels\\times filtersize+bias)\\times channels=(64\\times3\\times3+1)\\times64$\n",
        "-> MaxPooling2D(2x2 픽셀을 1x1로 압축)\n",
        "Input: $(11, 11, 64)$ </br>\n",
        "Output: $(5, 5, 64)$, </br>\n",
        "-> Flatten(입력된 3차원 데이터를 1차원 배열로 재구성), 784 </br>\n",
        "Input: $(5, 5, 64)$ </br>\n",
        "Output: $1600=5\\times5\\times64$</br>\n",
        "-> Dense(입력된 배열을 연산 후 128 길이의 배열로 출력) + Relu, 128 </br>\n",
        "Input: $1600$ </br>\n",
        "Output: $128$ </br>\n",
        "-> Dense(입력된 배열을 연산 후 softmax를 통해 10개의 확률로 출력) + SoftMax, 10 </br>\n",
        "Input: $128$ </br>\n",
        "Output: $10$ </br>\n",
        "- 출력(10)\n",
        "\n",
        "\n",
        "손실 계산:\n",
        "*   **옵티마이저(optimizer)**: Adam(Adaptive Moment Estimation)\n",
        "*   **손실함수(loss, Loss Function)**: sparse_categorical_crossentropy(0,1,2,3 등의 정수 값의 라벨에 대한 다중 분류 손실함수)"
      ],
      "metadata": {
        "id": "Rk8FI2ckCtjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "ayVIhzZUI5T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hj6qmeIkJmLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습하기\n",
        "tf.keras.Model.fit(x, y)\n",
        "\n",
        "\n",
        "*   Input = training_images\n",
        "*   ouput = training_labels\n",
        "*   epochs = 학습의 반복 수"
      ],
      "metadata": {
        "id": "_DUtYZuXDzbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cdi2zr_JvrP",
        "outputId": "ed0a8da8-1037-4e71-b9f3-db1e806282c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 86s 44ms/step - loss: 0.4433 - accuracy: 0.8403\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.2956 - accuracy: 0.8911\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2486 - accuracy: 0.9079\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.2147 - accuracy: 0.9205\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.1874 - accuracy: 0.9310\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.1636 - accuracy: 0.9381\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 78s 42ms/step - loss: 0.1415 - accuracy: 0.9473\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.1248 - accuracy: 0.9529\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.1085 - accuracy: 0.9585\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 76s 40ms/step - loss: 0.0944 - accuracy: 0.9646\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0834 - accuracy: 0.9684\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 78s 42ms/step - loss: 0.0725 - accuracy: 0.9728\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0647 - accuracy: 0.9751\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0562 - accuracy: 0.9792\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0514 - accuracy: 0.9810\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0465 - accuracy: 0.9824\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0418 - accuracy: 0.9844\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0399 - accuracy: 0.9853\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0356 - accuracy: 0.9866\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 83s 44ms/step - loss: 0.0311 - accuracy: 0.9891\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0336 - accuracy: 0.9878\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0309 - accuracy: 0.9886\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0309 - accuracy: 0.9889\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0280 - accuracy: 0.9905\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0284 - accuracy: 0.9901\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0248 - accuracy: 0.9913\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0258 - accuracy: 0.9910\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0236 - accuracy: 0.9917\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0242 - accuracy: 0.9916\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0229 - accuracy: 0.9919\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0227 - accuracy: 0.9924\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0197 - accuracy: 0.9935\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0227 - accuracy: 0.9925\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0228 - accuracy: 0.9928\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0203 - accuracy: 0.9934\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0180 - accuracy: 0.9939\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0206 - accuracy: 0.9929\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0199 - accuracy: 0.9937\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0191 - accuracy: 0.9937\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0195 - accuracy: 0.9939\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0163 - accuracy: 0.9944\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0197 - accuracy: 0.9941\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0182 - accuracy: 0.9941\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0184 - accuracy: 0.9940\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0144 - accuracy: 0.9955\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0192 - accuracy: 0.9934\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.0186 - accuracy: 0.9948\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0167 - accuracy: 0.9950\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0191 - accuracy: 0.9941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f4111badc30>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예측하기"
      ],
      "metadata": {
        "id": "D0GUYHjkmyXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e858f245-0f2c-4faf-ff72-d55225624aaf",
        "id": "WfnfwBanOMBM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 1.0087 - accuracy: 0.9072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0086950063705444, 0.9071999788284302]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* loss(error, 손실) = 1.0087\n",
        "* accuracy(정확도) = 90.72%"
      ],
      "metadata": {
        "id": "wOJQG4xgzdY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 출력 살펴보기"
      ],
      "metadata": {
        "id": "DcyW0kdTze9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piaCkpbrznZn",
        "outputId": "4d14aba5-8d8b-4843-a530-955e331aa656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step\n",
            "[0.0000000e+00 2.4038821e-33 2.5273516e-33 4.5973653e-35 4.2456518e-24\n",
            " 4.0134513e-31 0.0000000e+00 6.5647037e-20 8.0693845e-38 9.9999994e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델은 라벨 0-9 에대한 확률을 출력한다. 라벨 9의 확률이 99.9%로 가장 높아 실제 정답인 9와 일치한다."
      ],
      "metadata": {
        "id": "x0EYzh4ezxiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "완전 연결 계층으로만 이루어진 모델로 학습하였을 경우 86%였던 정확도가 90.72%로 크게 오른 모습을 보인다. 레이어 구조를 더 강화하고 에폭 수를 조절하면 더 좋은 결과를 보일 것으로 예측된다."
      ],
      "metadata": {
        "id": "oFGTdPfI4wra"
      }
    }
  ]
}